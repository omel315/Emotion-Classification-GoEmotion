{"cells":[{"cell_type":"markdown","metadata":{"id":"UqgXjjMVZ1uY"},"source":[]},{"cell_type":"markdown","metadata":{"id":"YntdfBea-24e"},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{"id":"AIILW4GZ_DWE"},"source":["\n","*   While analyzing the predictions made by the initial BERT model,  noticed that **some 'Neutral' comments were actually not 'Neutral'**\n","*   It appears that this class has been used like a **\"trash\" class** when manual labeling was difficult\n","*   Some samples were labeled with multiple labels, including the 'Neutral' emotion. However, **a sample cannot be 'Neutral' and also include other emotions**\n","*   Training a model on these **noisy data** could lead to increase the confusion between some emotions\n","* Let's try and train a new model by **filtering out the 'Neutral'** samples\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bmJO_oLA2ejV"},"source":["# 1 - Importing libraries and loading data"]},{"cell_type":"markdown","metadata":{"id":"maR0coq3F5rp"},"source":["## 1.1 - Installing and importing libraries"]},{"cell_type":"markdown","metadata":{"id":"z-WkRpzNBKRZ"},"source":["First, let's install the `transformers` library which contains thousands of pre-trained models, including BERT."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43569,"status":"ok","timestamp":1716322837669,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"3E2AKlZ1kzNa","outputId":"95676e8e-ffae-447c-b700-9a265b78831e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers\u003c0.20,\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.23.0-\u003etransformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.23.0-\u003etransformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (3.7)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers) (2024.2.2)\n","Collecting emoji\n","  Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions\u003e=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.11.0)\n","Installing collected packages: emoji\n","Successfully installed emoji-2.12.1\n","Collecting contractions\n","  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n","Collecting textsearch\u003e=0.0.21 (from contractions)\n","  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n","Collecting anyascii (from textsearch\u003e=0.0.21-\u003econtractions)\n","  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyahocorasick (from textsearch\u003e=0.0.21-\u003econtractions)\n","  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"]}],"source":["!pip install transformers\n","!pip install emoji\n","!pip install contractions"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15705,"status":"ok","timestamp":1716322853364,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"_wBm5n-nd3mz"},"outputs":[],"source":["# Data manipulation libraries\n","import sys, os\n","import pandas as pd\n","import numpy as np\n","import json\n","\n","import emoji\n","import contractions\n","import re\n","\n","# Scikit-learn packages\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","# Packages to define a BERT model\n","from transformers import TFBertModel, BertTokenizerFast, BertConfig\n","\n","# Keras and TensorFlow packages\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras import backend as K\n","from tensorflow.keras.layers import Input, Dropout, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.initializers import TruncatedNormal"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28779,"status":"ok","timestamp":1716322882130,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"CcGjMGCU8edq","outputId":"c043f7fd-4a3b-44a8-d46a-e6deb9d4a73c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"v6SjRuZCGQq7"},"source":["## 1.2 - Loading datasets and lists of emotions"]},{"cell_type":"markdown","metadata":{"id":"C4GNLM5oEOKu"},"source":["First, let's load our clean data."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7261,"status":"ok","timestamp":1716322889386,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"kXcnOj1nlnrb","outputId":"830425cd-cc47-438c-dcaf-5918fa5dbf54"},"outputs":[{"name":"stdout","output_type":"stream","text":["(147847, 30)\n","(31682, 30)\n","(31682, 30)\n"]}],"source":["# Importing train, validation and test datasets with preprocessed texts and labels\n","train_GE = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Thesis_Work/Thesis-II/DataFiles/full_dataset/train_dataset.csv\")\n","val_GE = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Thesis_Work/Thesis-II/DataFiles/full_dataset/validation_dataset.csv\")\n","test_GE = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Thesis_Work/Thesis-II/DataFiles/full_dataset/test_dataset.csv\")\n","\n","# Shape validation\n","print(train_GE.shape)\n","print(val_GE.shape)\n","print(test_GE.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"LpawvOCVEgCd"},"source":["Let's also load the lists of emotions from GoEmotions taxonomies **excluding the the 'Neutral' emotion** this time."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":893,"status":"ok","timestamp":1716322890240,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"HKI8gFsUEayQ","outputId":"682eb458-7bb3-49c3-a01b-970af5359812"},"outputs":[{"name":"stdout","output_type":"stream","text":["Emotions on GoEmotions taxonomy are : \n","['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise']\n","\n"]}],"source":["# Loading emotion labels for GoEmotions taxonomy\n","with open(\"/content/drive/MyDrive/Colab Notebooks/Thesis_Work/Thesis-II/DataFiles/full_dataset/emotions.txt\", \"r\") as file:\n","    GE_taxonomy = file.read().split(\"\\n\")\n","GE_taxonomy.remove('neutral')\n","print(\"Emotions on GoEmotions taxonomy are : \\n{}\".format(GE_taxonomy))\n","\n","print()\n"]},{"cell_type":"markdown","metadata":{"id":"ySfCRmWXQB3D"},"source":["## 1.3 - Filtering out the 'Neutral' only samples"]},{"cell_type":"markdown","metadata":{"id":"7e2ZikRMQLhg"},"source":["First, we need to drop the 'Neutral' emotion from all datasets."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1716322890240,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"-ueyGMWoQAdN"},"outputs":[],"source":["train_GE = train_GE.drop(columns=['neutral'])\n","val_GE = val_GE.drop(columns=['neutral'])\n","test_GE = test_GE.drop(columns=['neutral'])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":516},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1716322890241,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"y3q-YSnPsaxn","outputId":"ff2a3a36-2bd2-49ee-d3f2-69bc722b615d"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_GE"},"text/html":["\n","  \u003cdiv id=\"df-4512fcc6-f871-4572-ba26-42f59c12bda3\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ecleaned_text\u003c/th\u003e\n","      \u003cth\u003eemotion\u003c/th\u003e\n","      \u003cth\u003eadmiration\u003c/th\u003e\n","      \u003cth\u003eamusement\u003c/th\u003e\n","      \u003cth\u003eanger\u003c/th\u003e\n","      \u003cth\u003eannoyance\u003c/th\u003e\n","      \u003cth\u003eapproval\u003c/th\u003e\n","      \u003cth\u003ecaring\u003c/th\u003e\n","      \u003cth\u003econfusion\u003c/th\u003e\n","      \u003cth\u003ecuriosity\u003c/th\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003cth\u003ejoy\u003c/th\u003e\n","      \u003cth\u003elove\u003c/th\u003e\n","      \u003cth\u003enervousness\u003c/th\u003e\n","      \u003cth\u003eoptimism\u003c/th\u003e\n","      \u003cth\u003epride\u003c/th\u003e\n","      \u003cth\u003erealization\u003c/th\u003e\n","      \u003cth\u003erelief\u003c/th\u003e\n","      \u003cth\u003eremorse\u003c/th\u003e\n","      \u003cth\u003esadness\u003c/th\u003e\n","      \u003cth\u003esurprise\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003ei was born in 98 so i feel like your 98 loss i...\u003c/td\u003e\n","      \u003ctd\u003eapproval\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003ewow, you all are heroes!\u003c/td\u003e\n","      \u003ctd\u003ecuriosity\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eif its not obvious everyone is having issues w...\u003c/td\u003e\n","      \u003ctd\u003erealization\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003ethis architecture will be treasured even more ...\u003c/td\u003e\n","      \u003ctd\u003eneutral\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003ethat sucks, i hope you find the finances to be...\u003c/td\u003e\n","      \u003ctd\u003enervousness\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e5 rows × 29 columns\u003c/p\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4512fcc6-f871-4572-ba26-42f59c12bda3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-4512fcc6-f871-4572-ba26-42f59c12bda3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4512fcc6-f871-4572-ba26-42f59c12bda3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","\u003cdiv id=\"df-b9d34996-4813-4866-89b1-b3888cb79099\"\u003e\n","  \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9d34996-4813-4866-89b1-b3888cb79099')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","  \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","  \u003cscript\u003e\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() =\u003e {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b9d34996-4813-4866-89b1-b3888cb79099 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  \u003c/script\u003e\n","\u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["                                        cleaned_text      emotion  admiration  \\\n","0  i was born in 98 so i feel like your 98 loss i...     approval           0   \n","1                          wow, you all are heroes!     curiosity           0   \n","2  if its not obvious everyone is having issues w...  realization           0   \n","3  this architecture will be treasured even more ...      neutral           0   \n","4  that sucks, i hope you find the finances to be...  nervousness           0   \n","\n","   amusement  anger  annoyance  approval  caring  confusion  curiosity  ...  \\\n","0          0      0          0         1       0          0          0  ...   \n","1          0      0          0         0       0          0          1  ...   \n","2          0      0          0         0       0          0          0  ...   \n","3          0      0          0         0       0          0          0  ...   \n","4          0      0          0         0       0          0          0  ...   \n","\n","   joy  love  nervousness  optimism  pride  realization  relief  remorse  \\\n","0    0     0            0         0      0            0       0        0   \n","1    0     0            0         0      0            0       0        0   \n","2    0     0            0         0      0            1       0        0   \n","3    0     0            0         0      0            0       0        0   \n","4    0     0            1         1      0            0       0        0   \n","\n","   sadness  surprise  \n","0        0         0  \n","1        0         1  \n","2        0         0  \n","3        0         0  \n","4        0         0  \n","\n","[5 rows x 29 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_GE.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1716322890241,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"E7_gJAi1sb9x","outputId":"b06eb9bd-84c2-4d14-d056-e40d56e49ddb"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                        cleaned_text  admiration  amusement  \\\n","0  i was born in 98 so i feel like your 98 loss i...           0          0   \n","1                          wow, you all are heroes!            0          0   \n","2  if its not obvious everyone is having issues w...           0          0   \n","3  this architecture will be treasured even more ...           0          0   \n","4  that sucks, i hope you find the finances to be...           0          0   \n","\n","   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  joy  \\\n","0      0          0         1       0          0          0       0  ...    0   \n","1      0          0         0       0          0          1       0  ...    0   \n","2      0          0         0       0          0          0       0  ...    0   \n","3      0          0         0       0          0          0       0  ...    0   \n","4      0          0         0       0          0          0       0  ...    0   \n","\n","   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n","0     0            0         0      0            0       0        0        0   \n","1     0            0         0      0            0       0        0        0   \n","2     0            0         0      0            1       0        0        0   \n","3     0            0         0      0            0       0        0        0   \n","4     0            1         1      0            0       0        0        0   \n","\n","   surprise  \n","0         0  \n","1         1  \n","2         0  \n","3         0  \n","4         0  \n","\n","[5 rows x 28 columns]\n","                                        cleaned_text  admiration  amusement  \\\n","0                           i had the biggest smile!           1          0   \n","1  minimalist aesthetic stuff that does not look ...           0          0   \n","2  i have seen it too. i think it was an honest m...           0          0   \n","3                   i am not offended. just curious.           0          0   \n","4     lol they were trying so hard to get that viral           0          1   \n","\n","   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  joy  \\\n","0      0          0         0       0          0          0       0  ...    0   \n","1      0          0         0       0          0          0       0  ...    0   \n","2      0          0         1       0          0          0       0  ...    0   \n","3      0          0         0       0          0          1       0  ...    0   \n","4      0          0         0       0          0          0       0  ...    0   \n","\n","   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n","0     0            0         0      0            0       0        0        0   \n","1     0            0         0      0            0       0        0        0   \n","2     0            0         0      0            0       0        0        0   \n","3     0            0         0      0            0       0        0        0   \n","4     0            0         0      0            0       0        0        0   \n","\n","   surprise  \n","0         0  \n","1         0  \n","2         0  \n","3         0  \n","4         0  \n","\n","[5 rows x 28 columns]\n","                                        cleaned_text  admiration  amusement  \\\n","0  the situation never should have gotten to that...           0          0   \n","1          a surprise to be sure, but a welcome one.           0          0   \n","2  oh yeah? name one nature reserve or park and h...           0          0   \n","3  how stupid are you, if you do not ralize its s...           0          0   \n","4  no, that is how you find the nurses who work a...           0          0   \n","\n","   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  joy  \\\n","0      0          0         1       0          0          0       0  ...    0   \n","1      0          0         0       0          0          0       0  ...    0   \n","2      0          0         0       0          0          1       0  ...    0   \n","3      1          0         0       0          0          0       0  ...    0   \n","4      0          0         0       0          0          0       0  ...    0   \n","\n","   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n","0     0            0         0      0            0       0        0        0   \n","1     0            0         0      0            0       0        0        0   \n","2     0            0         0      0            0       0        0        0   \n","3     0            0         0      0            0       0        0        0   \n","4     0            0         0      0            0       0        0        0   \n","\n","   surprise  \n","0         0  \n","1         0  \n","2         0  \n","3         0  \n","4         0  \n","\n","[5 rows x 28 columns]\n"]}],"source":["# Drop the 'emotion' column\n","train_GE = train_GE.drop(columns=['emotion'], errors='ignore')\n","val_GE = val_GE.drop(columns=['emotion'], errors='ignore')\n","test_GE = test_GE.drop(columns=['emotion'], errors='ignore')\n","\n","# Display the first few rows of each dataframe to verify\n","print(train_GE.head())\n","print(val_GE.head())\n","print(test_GE.head())"]},{"cell_type":"markdown","metadata":{"id":"nD-C7i2EQXqL"},"source":["Then, we need remove all the samples that have been left without a label."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12501,"status":"ok","timestamp":1716322902734,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"LX2MtKYhRWbu","outputId":"8a3fb89e-f3f3-4112-db7f-b1a2e128baff"},"outputs":[{"name":"stdout","output_type":"stream","text":["(106728, 28)\n","(22941, 28)\n","(22847, 28)\n"]}],"source":["# Removing samples with only 0 in their labels\n","train_GE = train_GE.loc[ train_GE.apply(lambda x: sum(x[1:]), axis=1)\u003e0 ]\n","val_GE = val_GE.loc[ val_GE.apply(lambda x: sum(x[1:]), axis=1)\u003e0 ]\n","test_GE = test_GE.loc[ test_GE.apply(lambda x: sum(x[1:]), axis=1)\u003e0 ]\n","\n","# Shape validation\n","print(train_GE.shape)\n","print(val_GE.shape)\n","print(test_GE.shape)\n","\n","#Actual (147847, 30)|(31682, 30)|(31682, 30)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1716322902735,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"jQTYvnE5RzM0","outputId":"0a80d153-8f42-4912-dfd7-73e4bd41ccfb"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"},"text/html":["\n","  \u003cdiv id=\"df-be6b8196-f688-4810-af7c-38ec7a0d7eeb\" class=\"colab-df-container\"\u003e\n","    \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ecleaned_text\u003c/th\u003e\n","      \u003cth\u003eadmiration\u003c/th\u003e\n","      \u003cth\u003eamusement\u003c/th\u003e\n","      \u003cth\u003eanger\u003c/th\u003e\n","      \u003cth\u003eannoyance\u003c/th\u003e\n","      \u003cth\u003eapproval\u003c/th\u003e\n","      \u003cth\u003ecaring\u003c/th\u003e\n","      \u003cth\u003econfusion\u003c/th\u003e\n","      \u003cth\u003ecuriosity\u003c/th\u003e\n","      \u003cth\u003edesire\u003c/th\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003cth\u003ejoy\u003c/th\u003e\n","      \u003cth\u003elove\u003c/th\u003e\n","      \u003cth\u003enervousness\u003c/th\u003e\n","      \u003cth\u003eoptimism\u003c/th\u003e\n","      \u003cth\u003epride\u003c/th\u003e\n","      \u003cth\u003erealization\u003c/th\u003e\n","      \u003cth\u003erelief\u003c/th\u003e\n","      \u003cth\u003eremorse\u003c/th\u003e\n","      \u003cth\u003esadness\u003c/th\u003e\n","      \u003cth\u003esurprise\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003ei had the biggest smile!\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eminimalist aesthetic stuff that does not look ...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003ei have seen it too. i think it was an honest m...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e3 rows × 28 columns\u003c/p\u003e\n","\u003c/div\u003e\n","    \u003cdiv class=\"colab-df-buttons\"\u003e\n","\n","  \u003cdiv class=\"colab-df-container\"\u003e\n","    \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be6b8196-f688-4810-af7c-38ec7a0d7eeb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\"\u003e\n","\n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\"\u003e\n","    \u003cpath d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/\u003e\n","  \u003c/svg\u003e\n","    \u003c/button\u003e\n","\n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","    \u003cscript\u003e\n","      const buttonEl =\n","        document.querySelector('#df-be6b8196-f688-4810-af7c-38ec7a0d7eeb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-be6b8196-f688-4810-af7c-38ec7a0d7eeb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    \u003c/script\u003e\n","  \u003c/div\u003e\n","\n","\n","\u003cdiv id=\"df-66ef1198-a8b6-420e-8bc1-506f8366b534\"\u003e\n","  \u003cbutton class=\"colab-df-quickchart\" onclick=\"quickchart('df-66ef1198-a8b6-420e-8bc1-506f8366b534')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\"\u003e\n","\n","\u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\"\u003e\n","    \u003cg\u003e\n","        \u003cpath d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/\u003e\n","    \u003c/g\u003e\n","\u003c/svg\u003e\n","  \u003c/button\u003e\n","\n","\u003cstyle\u003e\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","\u003c/style\u003e\n","\n","  \u003cscript\u003e\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() =\u003e {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-66ef1198-a8b6-420e-8bc1-506f8366b534 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  \u003c/script\u003e\n","\u003c/div\u003e\n","\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n"],"text/plain":["                                        cleaned_text  admiration  amusement  \\\n","0                           i had the biggest smile!           1          0   \n","1  minimalist aesthetic stuff that does not look ...           0          0   \n","2  i have seen it too. i think it was an honest m...           0          0   \n","\n","   anger  annoyance  approval  caring  confusion  curiosity  desire  ...  joy  \\\n","0      0          0         0       0          0          0       0  ...    0   \n","1      0          0         0       0          0          0       0  ...    0   \n","2      0          0         1       0          0          0       0  ...    0   \n","\n","   love  nervousness  optimism  pride  realization  relief  remorse  sadness  \\\n","0     0            0         0      0            0       0        0        0   \n","1     0            0         0      0            0       0        0        0   \n","2     0            0         0      0            0       0        0        0   \n","\n","   surprise  \n","0         0  \n","1         0  \n","2         0  \n","\n","[3 rows x 28 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# Preview of data\n","display(val_GE.head(3))"]},{"cell_type":"markdown","metadata":{"id":"hl17G9t6UBzc"},"source":["Doing so, we have **decreased the number of samples by nearly 30%** of the original data."]},{"cell_type":"markdown","metadata":{"id":"yHTh1kSTHOQ7"},"source":["#2 - Modeling : BERT (Bidirectional Encoder Representations from Transformers)"]},{"cell_type":"markdown","metadata":{"id":"JwNGgNJ8Gx_X"},"source":["Now we can go ahead and start defining our BERT-based model."]},{"cell_type":"markdown","metadata":{"id":"hjvKpAysH1a3"},"source":["##2.1 - Configuration of the base model"]},{"cell_type":"markdown","metadata":{"id":"W-8Fdf8PHC8d"},"source":["First of all, let's define a `max_length` variable. This variable sets a fixed length of sequences to be fed to our model. Therefore, sequences will be either truncated if larger than this value, or completed using padding if smaller. To avoid truncating, we fix this value according to the largest sample of our data."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1716322920037,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"BBY58cNul4aH","outputId":"a6f3fdda-3b80-4828-9f84-e0e198f5c1e8"},"outputs":[{"data":{"text/plain":["34"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Computing max length of samples\n","full_text = pd.concat([train_GE['cleaned_text'], val_GE['cleaned_text'], test_GE['cleaned_text']])\n","max_length = full_text.apply(lambda x: len(x.split())).max()\n","max_length"]},{"cell_type":"markdown","metadata":{"id":"sdTKxbwTH8SF"},"source":["We are going to use BERT's base model which contains almost 110 M trainable parameters.\n","\n","Also, in order to match the tokenization and vocabulary used during the training, we are going to use a BERT tokenizer."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":11440,"status":"ok","timestamp":1716322937010,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"867vqvnTmI_F","outputId":"b212f8b2-c619-4a33-d775-9df8c8a6fb33"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6b02726d4f3435da92c6a4bb316c51f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a14f755a4af46f3b4f6b8000d1f1f28","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19a8cda9d42e4ff7aef64630d225be28","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cc8837f1bf24405b371a1167fbf8f0a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76f52e064ad8400fb36de2a60da89fff","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}],"source":["# Importing BERT pre-trained model and tokenizer\n","model_name = 'bert-base-uncased'\n","config = BertConfig.from_pretrained(model_name, output_hidden_states=False)\n","tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n","transformer_model = TFBertModel.from_pretrained(model_name, config = config)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5OHqPiqVIhB9"},"source":["## 2.2 - Definition of the model architecture"]},{"cell_type":"markdown","metadata":{"id":"bsNfi4DxJdtC"},"source":["Now that everything is in place, we can create a model based on BERT's main layer, and replace the top layers to reach our main objective (multi-label classification accross **27 possible emotions**)."]},{"cell_type":"markdown","metadata":{"id":"w1eM3XtfKFvm"},"source":["Our model takes three inputs that result from tokenization:\n","\n","*   `input_ids`: indices of input sequence tokens in the vocabulary\n","*   `token_ids`: Segment token indices to indicate first and second portions of the inputs.   0 for sentence A and 1 for sentence B\n","*   `attention mask`: Mask to avoid performing attention on padding token indices.  0 for masked and 1 for not masked\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gqxw9LYjm58O"},"outputs":[],"source":["# # function for creating BERT based model\n","# def create_model(nb_labels):\n","\n","#   # Load the MainLayer\n","#   bert = transformer_model.layers[0]\n","\n","#   # Build the model inputs\n","#   input_ids = tf.keras.Input(shape=(max_length,), name='input_ids', dtype='int32')\n","#   attention_mask = tf.keras.Input(shape=(max_length,), name='attention_mask', dtype='int32')\n","#   token_ids = tf.keras.Input(shape=(max_length,), name='token_ids', dtype='int32')\n","#   inputs = {'input_ids': input_ids, 'attention_mask': attention_mask, 'token_ids': token_ids}\n","\n","#   # Load the Transformers BERT model as a layer in a Keras model\n","#   bert_model = bert(inputs)[1]\n","#   dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n","#   pooled_output = dropout(bert_model, training=False)\n","\n","#   # Then build the model output\n","#   emotion = Dense(units=nb_labels, activation=\"sigmoid\", kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='emotion')(pooled_output)\n","#   outputs = emotion\n","\n","#   # And combine it all in a model object\n","#   model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel')\n","\n","#   return model"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1716322961793,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"CSxHnk9-w1d-"},"outputs":[],"source":["def create_model(nb_labels):\n","    # Load the MainLayer\n","    bert = transformer_model.layers[0]\n","\n","    # Build the model inputs\n","    input_ids = tf.keras.Input(shape=(max_length,), name='input_ids', dtype='int32')\n","    attention_mask = tf.keras.Input(shape=(max_length,), name='attention_mask', dtype='int32')\n","    token_ids = tf.keras.Input(shape=(max_length,), name='token_ids', dtype='int32')\n","\n","    # Load the Transformers BERT model as a layer in a Keras model\n","    bert_model = bert({'input_ids': input_ids, 'attention_mask': attention_mask, 'token_type_ids': token_ids})[1]\n","\n","    # Pass all three inputs to BERT\n","    dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n","    pooled_output = dropout(bert_model, training=False)\n","\n","    # Build the model output\n","    emotion = Dense(units=nb_labels, activation=\"sigmoid\", kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='emotion')(pooled_output)\n","    outputs = emotion\n","\n","    # And combine it all in a model object\n","    model = Model(inputs=[input_ids, attention_mask, token_ids], outputs=outputs, name='BERT_MultiLabel')\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"cSJJ5d6VNNvh"},"source":["We use here a `sigmoid` activation function in the last dense layer that is better suited than a `softmax` activation function. In fact, `softmax` shrinks output probabilities for each label so that the sum of probabilities is 1. In our case, each label (emotion) can independently have a probability between 0 and 1, and `sigmoid` allows that."]},{"cell_type":"markdown","metadata":{"id":"IAA-SpCMOFpf"},"source":["We can now create our model using 27 labels and visualize a summary."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23221,"status":"ok","timestamp":1716323133645,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"rGW1AxI0nIxK","outputId":"ba2de86b-05c7-4294-addb-cfdef03bf725"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   \u003ctf.Variable 'emotion/kernel:0' shape=(768, 27) dtype=float32\u003e. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n","WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.nn.bias_add), but are not present in its tracked objects:   \u003ctf.Variable 'emotion/bias:0' shape=(27,) dtype=float32\u003e. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"BERT_MultiLabel\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n","==================================================================================================\n","Total params: 109482240 (417.64 MB)\n","Trainable params: 109482240 (417.64 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}],"source":["# Creating a model instance\n","model = create_model(27)\n","\n","# Take a look at the model\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"PNVRanuLI_8j"},"source":["##2.3 - Data preprocessing and model training"]},{"cell_type":"markdown","metadata":{"id":"PAIwoQYvJKQb"},"source":["###2.3.1 - Tokenizing data"]},{"cell_type":"markdown","metadata":{"id":"KbfABovvO8f6"},"source":["Let's go ahead and process our data. We will first separate texts from labels in the train, validation and test datasets, and then tokenize the texts using the BERT tokenizer."]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":16196,"status":"ok","timestamp":1716323158320,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"XAopOFF1nzUS"},"outputs":[],"source":["# Creating train, validation and test variables\n","X_train = train_GE['cleaned_text']\n","y_train = train_GE.loc[:, GE_taxonomy].values.astype(float)\n","\n","X_val = val_GE['cleaned_text']\n","y_val = val_GE.loc[:, GE_taxonomy].values.astype(float)\n","\n","X_test = test_GE['cleaned_text']\n","y_test = test_GE.loc[:, GE_taxonomy].values.astype(float)\n","\n","# Tokenizing train data\n","train_token = tokenizer(\n","    text = X_train.to_list(),\n","    add_special_tokens = True,\n","    max_length = max_length,\n","    truncation = True,\n","    padding = 'max_length',\n","    return_tensors = 'tf',\n","    return_token_type_ids = True,\n","    return_attention_mask = True,\n","    verbose = True)\n","\n","# Tokenizing valisation data\n","val_token = tokenizer(\n","    text = X_val.to_list(),\n","    add_special_tokens = True,\n","    max_length = max_length,\n","    truncation = True,\n","    padding = 'max_length',\n","    return_tensors = 'tf',\n","    return_token_type_ids = True,\n","    return_attention_mask = True,\n","    verbose = True)\n","\n","# Tokenizing test data\n","test_token = tokenizer(\n","    text = X_test.to_list(),\n","    add_special_tokens = True,\n","    max_length = max_length,\n","    truncation = True,\n","    padding = 'max_length',\n","    return_tensors = 'tf',\n","    return_token_type_ids = True,\n","    return_attention_mask = True,\n","    verbose = True)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1716323158320,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"HMhCqsYipbys"},"outputs":[],"source":["# Creating BERT compatible inputs with Input Ids, attention masks and token Ids\n","train = {'input_ids': train_token['input_ids'], 'attention_mask': train_token['attention_mask'],'token_ids': train_token['token_type_ids']}\n","val = {'input_ids': val_token['input_ids'], 'attention_mask': val_token['attention_mask'],'token_ids': val_token['token_type_ids']}\n","test = {'input_ids': test_token['input_ids'], 'attention_mask': test_token['attention_mask'],'token_ids': test_token['token_type_ids']}"]},{"cell_type":"markdown","metadata":{"id":"Ex7HpdObPjHk"},"source":["During the training phase, we our going to use batches of 16 samples. After each epoch, data will be shuffled. Let's create TensorFlow tensors accordingly."]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":451,"status":"ok","timestamp":1716323161221,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"31_D_Novp1gd"},"outputs":[],"source":["# Creating TF tensors\n","train_tensor = tf.data.Dataset.from_tensor_slices((train, y_train)).shuffle(len(train)).batch(16)\n","val_tensor = tf.data.Dataset.from_tensor_slices((val, y_val)).shuffle(len(val)).batch(16)\n","test_tensor = tf.data.Dataset.from_tensor_slices((test, y_test)).shuffle(len(test)).batch(16)"]},{"cell_type":"markdown","metadata":{"id":"_onjkMzaJfEZ"},"source":["### 2.3.2 - Class weights for multi-label and custom loss function"]},{"cell_type":"markdown","metadata":{"id":"M5RVU6ArQyTa"},"source":["Training requires to monitor the loss function and eventually some other metrics to see how the model behaves throughout the epochs.\n","\n","Therefore, we need to define a weighted loss function that takes into account  class weights in our multi-label case.\n","\n","First, we need to compute class weights."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MswUN2pOxOor"},"outputs":[],"source":["# # Function for calculating multilabel class weights\n","# def calculating_class_weights(y_true):\n","#     number_dim = np.shape(y_true)[1]\n","#     weights = np.empty([number_dim, 2])\n","#     for i in range(number_dim):\n","#         weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])\n","#     return weights\n","\n","# class_weights = calculating_class_weights(y_train)"]},{"cell_type":"markdown","metadata":{"id":"1dXWrQ2rSyTz"},"source":["Then, we can define a custom crossentropy function in which we multiply the weights."]},{"cell_type":"markdown","metadata":{"id":"uLp0d2ITJ3Eq"},"source":["###2.3.3 - Model training"]},{"cell_type":"markdown","metadata":{"id":"ytcJQCODTyl4"},"source":["Everything is ready, we can now start training our model.\n","\n","We chose not to exceed 4 epochs to train our model as it will most likely start to overfit our data."]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1021,"status":"ok","timestamp":1716323174995,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"BSD0nYdABWI3"},"outputs":[],"source":["\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","# Function for calculating multilabel class weights\n","def calculating_class_weights(y_true):\n","    number_dim = np.shape(y_true)[1]\n","    weights = np.empty([number_dim, 2])\n","    for i in range(number_dim):\n","        unique_classes = np.unique(y_true[:, i])\n","        weights[i] = compute_class_weight('balanced', classes=unique_classes, y=y_true[:, i])\n","    return weights\n","\n","class_weights = calculating_class_weights(y_train)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":569,"status":"ok","timestamp":1716323177249,"user":{"displayName":"8732 Omel","userId":"13043925165829484027"},"user_tz":-300},"id":"GmvwQsFx2Oxa"},"outputs":[],"source":["# Custom loss function for multilabel\n","def get_weighted_loss(weights):\n","    def weighted_loss(y_true, y_pred):\n","        return K.mean((weights[:,0]**(1-y_true))*(weights[:,1]**(y_true))*K.binary_crossentropy(y_true, y_pred), axis=-1)\n","    return weighted_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"0eo6-2XD2ZIP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/4\n","1069/6671 [===\u003e..........................] - ETA: 10:24:27 - loss: 0.5548"]}],"source":["# Set an optimizer\n","optimizer = Adam(\n","    learning_rate=3.e-05\n","    )\n","\n","# Set loss\n","loss = get_weighted_loss(class_weights)\n","\n","# Compile the model\n","model.compile(\n","    optimizer = optimizer,\n","    loss = loss)\n","\n","# train the model\n","history = model.fit(train_tensor,\n","                    epochs=4,\n","                    validation_data=val_tensor,\n","                    )"]},{"cell_type":"markdown","metadata":{"id":"4znNuCgxRUuv"},"source":["## 2.4 - Model evaluation"]},{"cell_type":"markdown","metadata":{"id":"rw2Ovil8cw1M"},"source":["### 2.4.1 - Evaluation on GoEmotions taxonomy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OF-AkXcmjsNT"},"outputs":[],"source":["# # Save model weights\n","# model.save_weights('/content/drive/MyDrive/Colab Notebooks/Thesis_Work/Thesis-II/DataFiles/full_dataset/emotions.txt/bert-weights.hdf5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0SaXJdo53d2"},"outputs":[],"source":["# Define the directory path where you want to save the model weights\n","directory_path = '/content/drive/MyDrive/Colab Notebooks/Thesis_Work/Thesis-II/DataFiles/full_dataset/'\n","\n","# Save model weights\n","model.save_weights(directory_path + 'bert-weights.hdf5')"]},{"cell_type":"markdown","metadata":{"id":"txhLFoByV53b"},"source":["Let's generate predictions on test data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jrVVKNF9VjAN"},"outputs":[],"source":["# Making probability predictions on test data\n","y_pred_proba = model.predict(test)"]},{"cell_type":"markdown","metadata":{"id":"lEXHXyhPWCCr"},"source":["When making predictions, we only generate probabilities associated with each label. To predict actual labels, we need to add an additional step that transforms these probabilities into labels given a certain threshold.\n","\n","We define a function to do so with a default threshold set to 0.8."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdlRK7nt2Jr8"},"outputs":[],"source":["# from probabilities to labels using a given threshold\n","def proba_to_labels(y_pred_proba, threshold=0.8):\n","\n","    y_pred_labels = np.zeros_like(y_pred_proba)\n","\n","    for i in range(y_pred_proba.shape[0]):\n","        for j in range(y_pred_proba.shape[1]):\n","            if y_pred_proba[i][j] \u003e threshold:\n","                y_pred_labels[i][j] = 1\n","            else:\n","                y_pred_labels[i][j] = 0\n","\n","    return y_pred_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRzQNJ8bXWP9"},"outputs":[],"source":["# Generate labels\n","y_pred_labels = proba_to_labels(y_pred_proba)"]},{"cell_type":"markdown","metadata":{"id":"07pAgsrBWr2g"},"source":["Let's evaluate these predictions using the evaluation function we defined in the previous notebooks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KwgSu5mdW_S9"},"outputs":[],"source":["# Model evaluation function\n","def model_eval(y_true, y_pred_labels, emotions):\n","\n","    # Defining variables\n","    precision = []\n","    recall = []\n","    f1 = []\n","\n","    # Per emotion evaluation\n","    idx2emotion = {i: e for i, e in enumerate(emotions)}\n","\n","    for i in range(len(emotions)):\n","\n","        # Computing precision, recall and f1-score\n","        p, r, f1_score, _ = precision_recall_fscore_support(y_true[:, i], y_pred_labels[:, i], average=\"binary\")\n","\n","        # Append results in lists\n","        precision.append(round(p, 2))\n","        recall.append(round(r, 2))\n","        f1.append(round(f1_score, 2))\n","\n","    # Macro evaluation\n","    macro_p, macro_r, macro_f1_score, _ = precision_recall_fscore_support(y_true, y_pred_labels, average=\"macro\")\n","\n","    # Append results in lists\n","    precision.append(round(macro_p, 2))\n","    recall.append(round(macro_r, 2))\n","    f1.append(round(macro_f1_score, 2))\n","\n","    # Converting results to a dataframe\n","    df_results = pd.DataFrame({\"Precision\":precision, \"Recall\":recall, 'F1':f1})\n","    df_results.index = emotions+['MACRO-AVERAGE']\n","\n","    return df_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rW_rNrE_cN56"},"outputs":[],"source":["# Model evaluation\n","model_eval(y_test, y_pred_labels, GE_taxonomy)"]},{"cell_type":"markdown","metadata":{"id":"kHKrdAGgzzxL"},"source":["Looking at the results, we see that this model performs better than the previous one. It looks like **removing the noise brought by the 'Neutral' emotion helped to better distinguish the other emotions.**"]},{"cell_type":"markdown","metadata":{"id":"QiEfmN4zYWzp"},"source":["### 2.4.2 - Threshold optimization"]},{"cell_type":"markdown","metadata":{"id":"jJBpGoXFYmqX"},"source":["In the initial evaluation, we set an aribitrary threshold. However, we can also choose a threshold that maximizes a certain metric.\n","\n","We define a function that tests a certain number of possible thresholds, and returns the best threshold together with the best predicted labels and best macro f1-score."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mVoNZ3FsNZ_W"},"outputs":[],"source":["# Function that computes labels from probabilities and optimizes the threshold that maximizes f1-score\n","def proba_to_labels_opt(y_true, y_pred_proba):\n","\n","    '''\n","    Inputs:\n","        y_true: Ground truth labels\n","        y_pred_proba: predicted probabilities\n","\n","    Outputs :\n","        best_y_pred_labels: preticted labels associated with best threshold\n","        best_t: best threshold\n","        best_macro_f1: macro f1-score associated with predicted labels\n","    '''\n","\n","    # range of possible thresholds\n","    thresholds = np.arange(0.7, 0.99, 0.01)\n","\n","    # Computing threshold that maximizes macro f1-score\n","    best_y_pred_labels = np.zeros_like(y_pred_proba)\n","    best_t = 0\n","    best_macro_f1 = 0\n","\n","    # Iterating through possible thresholds\n","    for t in thresholds:\n","\n","        y_pred_labels = proba_to_labels(y_pred_proba, t)\n","\n","        _, _, macro_f1, _ = precision_recall_fscore_support(y_true, y_pred_labels, average=\"macro\")\n","\n","        if macro_f1 \u003e best_macro_f1:\n","            best_macro_f1 = macro_f1\n","            best_t = t\n","            best_y_pred_labels = y_pred_labels\n","\n","    return best_y_pred_labels, best_t, best_macro_f1"]},{"cell_type":"markdown","metadata":{"id":"R6S8iogIb051"},"source":["We can now apply this function to our predicted probabilities and compute optimized label predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LDKmAidZvIi"},"outputs":[],"source":["# Compute label predictions and corresponding optimal thresholds\n","y_pred_labels_opt, threshold_opt, macro_f1_opt = proba_to_labels_opt(y_test, y_pred_proba)\n","print(\"The model's threshold is {}\".format(threshold_opt))\n","print(\"The model's best macro-f1 is {}\".format(macro_f1_opt))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2TM1hZ1JZ31q"},"outputs":[],"source":["# Model evaluation : Precision, Recall, F-score\n","model_eval(y_test, y_pred_labels_opt, GE_taxonomy)"]},{"cell_type":"markdown","metadata":{"id":"EMYPEVAK0D89"},"source":["**Optimizing the threshold** helped us to **slightly improve** the model predictions."]},{"cell_type":"markdown","metadata":{"id":"J_ojzWhTUT2W"},"source":["## 2.5 - Make predictions"]},{"cell_type":"markdown","metadata":{"id":"sJABBqRVtlbk"},"source":["To make predictions on a new sample, it needs to be processed using all the different precessing steps we used."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tdTRJR_ZhVKI"},"outputs":[],"source":["# Retrieving initial preprocessings\n","def preprocess_corpus(x):\n","\n","    # Adding a space between words and punctation\n","    x = re.sub( r'([a-zA-Z\\[\\]])([,;.!?])', r'\\1 \\2', x)\n","    x = re.sub( r'([,;.!?])([a-zA-Z\\[\\]])', r'\\1 \\2', x)\n","\n","    # Demojize\n","    x = emoji.demojize(x)\n","\n","    # Expand contraction\n","    x = contractions.fix(x)\n","\n","    # Lower\n","    x = x.lower()\n","\n","    #correct some acronyms/typos/abbreviations\n","    x = re.sub(r\"lmao\", \"laughing my ass off\", x)\n","    x = re.sub(r\"amirite\", \"am i right\", x)\n","    x = re.sub(r\"\\b(tho)\\b\", \"though\", x)\n","    x = re.sub(r\"\\b(ikr)\\b\", \"i know right\", x)\n","    x = re.sub(r\"\\b(ya|u)\\b\", \"you\", x)\n","    x = re.sub(r\"\\b(eu)\\b\", \"europe\", x)\n","    x = re.sub(r\"\\b(da)\\b\", \"the\", x)\n","    x = re.sub(r\"\\b(dat)\\b\", \"that\", x)\n","    x = re.sub(r\"\\b(dats)\\b\", \"that is\", x)\n","    x = re.sub(r\"\\b(cuz)\\b\", \"because\", x)\n","    x = re.sub(r\"\\b(fkn)\\b\", \"fucking\", x)\n","    x = re.sub(r\"\\b(tbh)\\b\", \"to be honest\", x)\n","    x = re.sub(r\"\\b(tbf)\\b\", \"to be fair\", x)\n","    x = re.sub(r\"faux pas\", \"mistake\", x)\n","    x = re.sub(r\"\\b(btw)\\b\", \"by the way\", x)\n","    x = re.sub(r\"\\b(bs)\\b\", \"bullshit\", x)\n","    x = re.sub(r\"\\b(kinda)\\b\", \"kind of\", x)\n","    x = re.sub(r\"\\b(bruh)\\b\", \"bro\", x)\n","    x = re.sub(r\"\\b(w/e)\\b\", \"whatever\", x)\n","    x = re.sub(r\"\\b(w/)\\b\", \"with\", x)\n","    x = re.sub(r\"\\b(w/o)\\b\", \"without\", x)\n","    x = re.sub(r\"\\b(doj)\\b\", \"department of justice\", x)\n","\n","    # replace some words with multiple occurences of a letter, example \"coooool\" turns into --\u003e cool\n","    x = re.sub(r\"\\b(j+e{2,}z+e*)\\b\", \"jeez\", x)\n","    x = re.sub(r\"\\b(co+l+)\\b\", \"cool\", x)\n","    x = re.sub(r\"\\b(g+o+a+l+)\\b\", \"goal\", x)\n","    x = re.sub(r\"\\b(s+h+i+t+)\\b\", \"shit\", x)\n","    x = re.sub(r\"\\b(o+m+g+)\\b\", \"omg\", x)\n","    x = re.sub(r\"\\b(w+t+f+)\\b\", \"wtf\", x)\n","    x = re.sub(r\"\\b(w+h+a+t+)\\b\", \"what\", x)\n","    x = re.sub(r\"\\b(y+e+y+|y+a+y+|y+e+a+h+)\\b\", \"yeah\", x)\n","    x = re.sub(r\"\\b(w+o+w+)\\b\", \"wow\", x)\n","    x = re.sub(r\"\\b(w+h+y+)\\b\", \"why\", x)\n","    x = re.sub(r\"\\b(s+o+)\\b\", \"so\", x)\n","    x = re.sub(r\"\\b(f)\\b\", \"fuck\", x)\n","    x = re.sub(r\"\\b(w+h+o+p+s+)\\b\", \"whoops\", x)\n","    x = re.sub(r\"\\b(ofc)\\b\", \"of course\", x)\n","    x = re.sub(r\"\\b(the us)\\b\", \"usa\", x)\n","    x = re.sub(r\"\\b(gf)\\b\", \"girlfriend\", x)\n","    x = re.sub(r\"\\b(hr)\\b\", \"human ressources\", x)\n","    x = re.sub(r\"\\b(mh)\\b\", \"mental health\", x)\n","    x = re.sub(r\"\\b(idk)\\b\", \"i do not know\", x)\n","    x = re.sub(r\"\\b(gotcha)\\b\", \"i got you\", x)\n","    x = re.sub(r\"\\b(y+e+p+)\\b\", \"yes\", x)\n","    x = re.sub(r\"\\b(a*ha+h[ha]*|a*ha +h[ha]*)\\b\", \"haha\", x)\n","    x = re.sub(r\"\\b(o?l+o+l+[ol]*)\\b\", \"lol\", x)\n","    x = re.sub(r\"\\b(o*ho+h[ho]*|o*ho +h[ho]*)\\b\", \"ohoh\", x)\n","    x = re.sub(r\"\\b(o+h+)\\b\", \"oh\", x)\n","    x = re.sub(r\"\\b(a+h+)\\b\", \"ah\", x)\n","    x = re.sub(r\"\\b(u+h+)\\b\", \"uh\", x)\n","\n","    # Handling emojis\n","    x = re.sub(r\"\u003c3\", \" love \", x)\n","    x = re.sub(r\"xd\", \" smiling_face_with_open_mouth_and_tightly_closed_eyes \", x)\n","    x = re.sub(r\":\\)\", \" smiling_face \", x)\n","    x = re.sub(r\"^_^\", \" smiling_face \", x)\n","    x = re.sub(r\"\\*_\\*\", \" star_struck \", x)\n","    x = re.sub(r\":\\(\", \" frowning_face \", x)\n","    x = re.sub(r\":\\^\\(\", \" frowning_face \", x)\n","    x = re.sub(r\";\\(\", \" frowning_face \", x)\n","    x = re.sub(r\":\\/\",  \" confused_face\", x)\n","    x = re.sub(r\";\\)\",  \" wink\", x)\n","    x = re.sub(r\"\u003e__\u003c\",  \" unamused \", x)\n","    x = re.sub(r\"\\b([xo]+x*)\\b\", \" xoxo \", x)\n","    x = re.sub(r\"\\b(n+a+h+)\\b\", \"no\", x)\n","\n","    # Handling special cases of text\n","    x = re.sub(r\"h a m b e r d e r s\", \"hamberders\", x)\n","    x = re.sub(r\"b e n\", \"ben\", x)\n","    x = re.sub(r\"s a t i r e\", \"satire\", x)\n","    x = re.sub(r\"y i k e s\", \"yikes\", x)\n","    x = re.sub(r\"s p o i l e r\", \"spoiler\", x)\n","    x = re.sub(r\"thankyou\", \"thank you\", x)\n","    x = re.sub(r\"a^r^o^o^o^o^o^o^o^n^d\", \"around\", x)\n","\n","    # Remove special characters and numbers replace by space + remove double space\n","    x = re.sub(r\"\\b([.]{3,})\",\" dots \", x)\n","    x = re.sub(r\"[^A-Za-z!?_]+\",\" \", x)\n","    x = re.sub(r\"\\b([s])\\b *\",\"\", x)\n","    x = re.sub(r\" +\",\" \", x)\n","    x = x.strip()\n","\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"oCEftbxYy4hO"},"source":["Now we can define a prediction function that takes one or more samples, and outputs the detected emotions from the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bm-6OEi_1V6t"},"outputs":[],"source":["def predict_samples(text_samples, model, threshold):\n","\n","    # Text preprocessing and cleaning\n","    text_samples_clean = [preprocess_corpus(text) for text in text_samples]\n","\n","    # Tokenizing train data\n","    samples_token = tokenizer(\n","        text = text_samples_clean,\n","        add_special_tokens = True,\n","        max_length = max_length,\n","        truncation = True,\n","        padding = 'max_length',\n","        return_tensors = 'tf',\n","        return_token_type_ids = True,\n","        return_attention_mask = True,\n","        verbose = True,\n","    )\n","\n","    # Preparing to feed the model\n","    samples = {'input_ids': samples_token['input_ids'],\n","               'attention_mask': samples_token['attention_mask'],\n","               'token_ids': samples_token['token_type_ids']\n","              }\n","\n","    # Probability predictions\n","    samples_pred_proba = model.predict(samples)\n","\n","    # Label prediction using threshold\n","    samples_pred_labels = proba_to_labels(samples_pred_proba)\n","\n","    samples_pred_labels_df = pd.DataFrame(samples_pred_labels)\n","    samples_pred_labels_df = samples_pred_labels_df.apply(lambda x: [GE_taxonomy[i] for i in range(len(x)) if x[i]==1], axis=1)\n","\n","    #return list(samples_pred_labels_df)\n","    return pd.DataFrame({\"Text\":text_samples, \"Emotions\":list(samples_pred_labels_df)})"]},{"cell_type":"markdown","metadata":{"id":"XRKT57TEzaBs"},"source":["Let's try on few examples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQ_dctb0O-9A"},"outputs":[],"source":["# Predict samples\n","predict_samples([\"My favourite food is anything I didn't have to cook myself\", \"are you kiddin me ??!!\", \"red\"], model, threshold_opt)"]},{"cell_type":"markdown","metadata":{"id":"nWFLQoJR34fk"},"source":["Although the score is not very high, we see that the model **detects emotions that coherent**. Also, **when entering a neutral text such as \"red\", the model does not detect any emotion**."]},{"cell_type":"markdown","metadata":{"id":"5wbWDq2ih0qq"},"source":["# Conclusion"]},{"cell_type":"markdown","metadata":{"id":"PmYA0qoDh4qC"},"source":["*   In this notebook, we verified our assumption : **filtering out the 'Neutral' samples from the data allows to improve the model**.\n","\n","*   Not only **we better distinguish actual emotions**, but **we can also detect 'Neutral' comments**, **without teaching our model what is a 'Neutral' comment**."]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"019b152246004585a1bffa6c6edbd0ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"041e2290a7aa4ee2bd7efeed3b0c43bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ecc0deb13454c379092ee346be2d875","placeholder":"​","style":"IPY_MODEL_885b53cf4f054e24b1b4b6df3c9ac348","value":" 232k/232k [00:00\u0026lt;00:00, 2.68MB/s]"}},"048015c836014022951e5d2602d62c29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76e862ca977f4e50968e838ca09cc680","placeholder":"​","style":"IPY_MODEL_f14e591d3cce4e78bfa38f351b4d3b0d","value":"config.json: 100%"}},"0a14f755a4af46f3b4f6b8000d1f1f28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c49abc5d297347c2bfe0ebbc767eceff","IPY_MODEL_bbb8306809a24b8787c1945f6fe459d6","IPY_MODEL_29eeeb3679f847529694d64802bf02b2"],"layout":"IPY_MODEL_4f7671df193340c6b0ed29c8bf104429"}},"0e75610f643945368d60a6570cae95d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12882ba44dee48a68f16149cbb65af64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45aece7c6c0d43519e40aecc3324f796","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_393781d37eba4421b84a96aa2ef349c0","value":440449768}},"15ed33d12a6d479bb489511ab6f705fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1971bd4cb343440cb70d0202ec80ec19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea45172ac25c421d87ebf1840b3605a2","placeholder":"​","style":"IPY_MODEL_4654e8abf1a64c1daf7d2e20591d0bf6","value":"vocab.txt: 100%"}},"19a8cda9d42e4ff7aef64630d225be28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1971bd4cb343440cb70d0202ec80ec19","IPY_MODEL_657460296f7745b49f99739a40bf42e3","IPY_MODEL_041e2290a7aa4ee2bd7efeed3b0c43bb"],"layout":"IPY_MODEL_70befc734eab421ab8c4e17b16614f81"}},"26af0f8cff1d4b4e9bd0c88f458badd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29eeeb3679f847529694d64802bf02b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbcac4e751144668a1b90c21ba4175fe","placeholder":"​","style":"IPY_MODEL_15ed33d12a6d479bb489511ab6f705fb","value":" 48.0/48.0 [00:00\u0026lt;00:00, 1.23kB/s]"}},"393781d37eba4421b84a96aa2ef349c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39febdb093274279ac2c4e98d61c1d3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ecc0deb13454c379092ee346be2d875":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"416ea575490043a699373b8d1098abac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"435488e8deb24f6fb825a7b620081235":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_416ea575490043a699373b8d1098abac","placeholder":"​","style":"IPY_MODEL_9179aa5eb2b44274bb52e444419f70bb","value":"model.safetensors: 100%"}},"43672cc3f80c4e8bbf7d64f927c47e5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d5ce4d44dd54e869e3c58c89e63141b","placeholder":"​","style":"IPY_MODEL_94a49baa09464d26be629c08f8a2ef44","value":" 570/570 [00:00\u0026lt;00:00, 19.1kB/s]"}},"45aece7c6c0d43519e40aecc3324f796":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4654e8abf1a64c1daf7d2e20591d0bf6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f7671df193340c6b0ed29c8bf104429":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53613a130cef40a49d819857ff305154":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"596d6e0a2260476cb9943c8ada15c7d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ee06ddeb3174ce68b01f7ea5a9b2815":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62935317cef4404aa5c981e671d9a241":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"657460296f7745b49f99739a40bf42e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb182425f825451bbd534acecdc9a622","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac26786028594b9a9f1b269bb5b023b5","value":231508}},"6af78de6c9874b9c9708d0f0a0da98fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cc8837f1bf24405b371a1167fbf8f0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c71e23f569e448549bb0af31eba8d369","IPY_MODEL_6dedc6dc5d09444ea47a580a1ad8ea4a","IPY_MODEL_80b19f0591e24b438e310fc18dde2a16"],"layout":"IPY_MODEL_7e7c9354a107440cbf62da27b4391e00"}},"6dedc6dc5d09444ea47a580a1ad8ea4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e75610f643945368d60a6570cae95d1","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53613a130cef40a49d819857ff305154","value":466062}},"6e16ed88cdfd4470875e06af786cf0bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70befc734eab421ab8c4e17b16614f81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76e862ca977f4e50968e838ca09cc680":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76f52e064ad8400fb36de2a60da89fff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_435488e8deb24f6fb825a7b620081235","IPY_MODEL_12882ba44dee48a68f16149cbb65af64","IPY_MODEL_a5f052b70789444e86c4bf0d28e3897a"],"layout":"IPY_MODEL_bf3aa32cf44f4adb9ad9103bc5af6618"}},"7d5ce4d44dd54e869e3c58c89e63141b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e7c9354a107440cbf62da27b4391e00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80b19f0591e24b438e310fc18dde2a16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_596d6e0a2260476cb9943c8ada15c7d6","placeholder":"​","style":"IPY_MODEL_969a13efe9fa4b2f8d2e4629dbe20c1a","value":" 466k/466k [00:00\u0026lt;00:00, 3.03MB/s]"}},"885b53cf4f054e24b1b4b6df3c9ac348":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9179aa5eb2b44274bb52e444419f70bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94a49baa09464d26be629c08f8a2ef44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94d54a7dfcab476faf35214e692096c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"969a13efe9fa4b2f8d2e4629dbe20c1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5f052b70789444e86c4bf0d28e3897a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62935317cef4404aa5c981e671d9a241","placeholder":"​","style":"IPY_MODEL_6af78de6c9874b9c9708d0f0a0da98fa","value":" 440M/440M [00:03\u0026lt;00:00, 154MB/s]"}},"ac26786028594b9a9f1b269bb5b023b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6b02726d4f3435da92c6a4bb316c51f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_048015c836014022951e5d2602d62c29","IPY_MODEL_e0486db5b1a04fb08ced6273b5981430","IPY_MODEL_43672cc3f80c4e8bbf7d64f927c47e5f"],"layout":"IPY_MODEL_26af0f8cff1d4b4e9bd0c88f458badd6"}},"bbb8306809a24b8787c1945f6fe459d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e16ed88cdfd4470875e06af786cf0bd","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee3f262961fa420a8b12d047c04e298e","value":48}},"bbcac4e751144668a1b90c21ba4175fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf3aa32cf44f4adb9ad9103bc5af6618":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c49abc5d297347c2bfe0ebbc767eceff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e01d84b10df5443085fbc411a2e61dd6","placeholder":"​","style":"IPY_MODEL_94d54a7dfcab476faf35214e692096c8","value":"tokenizer_config.json: 100%"}},"c71e23f569e448549bb0af31eba8d369":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39febdb093274279ac2c4e98d61c1d3e","placeholder":"​","style":"IPY_MODEL_5ee06ddeb3174ce68b01f7ea5a9b2815","value":"tokenizer.json: 100%"}},"e01d84b10df5443085fbc411a2e61dd6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0486db5b1a04fb08ced6273b5981430":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_019b152246004585a1bffa6c6edbd0ff","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6a5d809bd4c43fcb4e59194400f1b3e","value":570}},"e6a5d809bd4c43fcb4e59194400f1b3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea45172ac25c421d87ebf1840b3605a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee3f262961fa420a8b12d047c04e298e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f14e591d3cce4e78bfa38f351b4d3b0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb182425f825451bbd534acecdc9a622":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}